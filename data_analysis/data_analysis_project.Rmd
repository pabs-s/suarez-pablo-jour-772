---
title: "data_analysis_project"
author: "Alisha Camacho, Steven Jacobs and Pablo Suarez"
date: "2023-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## INTRODUCTION

Welcome to the JOUR772 data analysis markdown file of Alisha Camacho, Steven Jacobs and Pablo Suarez. Below, we are analyzing a Kaggle data set containing data collected on board games from the BoardGameGeek (BGG) website in February 2021. BGG, the largest online collection of board game data, relies on its voluntary community to build its database by providing site contributions in the form of board game reviews, ratings, images, videos and live discussion forums, among others.

This data set incorporates those user contributions and contains information on roughly 20,000 board games scraped from the BGG rankings as of the date of collection by the original data set creators. It does not feature any unranked games, as those games do not meet the 30 vote threshold needed to be eligible for rankings.

Columns in this data set include a game's unique BGG ID, name, year published, minimum players required, maximum players allowed, average play time, minimum age required, number of users who rated the game, average rating, the BGG rank, complexity average, number of owned users, mechanics and domains.

***Link to the data set: <https://www.kaggle.com/datasets/andrewmvd/board-games/>***

## ***Project Milestone #1***

We were asked to craft newsworthy questions that we'd like to attempt to answer about this data set. Our questions include:

-   What is the relationship, if any, between average play-time and average rating?

-   How are the games for 4 or 5+ players rated differently or more frequently than games intended for fewer players? Same for solo games.

-   Measuring by year and decade, what are the top average board games, domains and mechanics?

-   How does the complexity of board games vary based on the recommended minimum age?

-   What are the highest-rated games that are the most owned and have the most users rated? How does this list compare to the BGG rankings?

-   What are the 25 oldest games in our data set, how much did they cost on release and how much do they cost now? Did they increase in price, and if so, does that follow the inflation rate?

## ***Project Milestone #2***

In this section of the project, we were tasked with creating our markdown file and accomplishing the following tasks:

-   Load and clean the core data set to prepare for analysis.

-   Show basic exploratory analysis to demonstrate an understanding of the data set. Include the number of rows and columns, any obvious limitations or flaws and any reasons why it might not be able to answer the research questions.

We began by loading our libraries and settings.

```{r}

# Turn off scientific notation
options(scipen=999)

# Load our libraries
library(tidyverse)
library(janitor)
library(refinr)
library(lubridate)
library(dplyr)
library(readr)
library(tidytext)

#install hash package if you need to
#install.packages("hash")
library(hash)

```

Next, we loaded in our core data set. Upon reading it in at first, we received this error message -- "Error in read.table(file = file, header = header, sep = sep, quote = quote, : more columns than column names". The error suggests that this CSV file is delimited by a character other than a comma. Our data set is separated instead by a semicolon, so we used the sep parameter when reading the file in to be able to view it properly.

Once the data set was properly loaded, we used the clean_names function to make all of the column headings lowercase. Then we focused on converting our columns into the proper data types. For the rating average and complexity average columns, these were initially imported as character type columns. Given that we might want to do further calculations with these average ratings, we converted them to numeric type columns. To do that, we first had to replace the commas within those columns to decimal points. We then used the mutate function to call in the columns and convert them as we've been taught.

We also converted the id and bgg_rank columns from an integer type to a character type as these are not numeric values we want to use in calculations, rather they are intended to serve as unique identifiers for the board games.

Here is the code showing how we imported and cleaned our data:

```{r}

bgg_dataset <- read.csv("data/bgg_dataset.csv", sep = ";") |>
  clean_names() |>
  mutate(mechanics = str_to_lower(mechanics))

bgg_dataset$rating_average <- gsub(",", ".", bgg_dataset$rating_average)
bgg_dataset$complexity_average <- gsub(",", ".", bgg_dataset$complexity_average)

bgg_dataset <- bgg_dataset |>
  mutate(id = as.character(id),
         bgg_rank = as.character(bgg_rank),
         rating_average = as.numeric(rating_average), 
         complexity_average = as.numeric(complexity_average))

glimpse(bgg_dataset)

```

Explanatory Analysis of the Data Set:

Number of Rows: 20,343

Number of Columns: 14

Obvious Limitations or Flaws:

-   We believe we are going to encounter some issues with how the data within the mechanics column is nested. The amount of information in each individual entry in that column will make it difficult to group or sort. We anticipate that we'll need to frequently filter results from that column. The same could be said for the domains column, although that column doesn't nearly have as much data nested within each row.

-   We wish that this data set included each game's price on release. This is outside data that we'd have to create a data frame for and merge it to our bgg_dataset (or a smaller data set) in order to answer our last question.

## ***Project Milestone #3***

For this milestone we were expected to complete the following tasks:

- Show an attempt to answer questions created during Milestone #1

We were also instructed by Ryan to limit our original questions and add two questions addressing the "mechanics" and "domains" columns.
Our two new questions:
- What are, by count, the most common mechanics among games in our data set? 

- What are the most popular domain types by year?

We then began working on some of our original questions: 

## Q1: What is the relationship, if any, between average play-time and average rating?

To identify whether there is a relationship between these two factors, we first grouped the data by the play_time column. Then we summarized to find the count of games within a certain play time value. We also summarized to find the average rating of games within these play time values. 

The most common play time for games in our data set is 30 minutes with 3,638. These games have an average rating of 6.17 out of 10. This was followed by 60 minutes, which had 3,003 games and an average score of 6.43, as well as 45 minutes with 2,207 games and an average rating of 6.35. 

```{r}

bgg_dataset |>
  group_by(play_time)|>
  summarise(count = n(), average_rating = mean(rating_average, na.rm = TRUE)) |>
  arrange(desc(count))

```

If we were to arrange this data in descending order by average rating, we would see smaller sample sizes of games with extremely long play times. The highest rated game by this arrangement method has a play time of 8,640 minutes and a rating of 9.12. However, the first play time window with a sample of over 500 games is 240 minutes with an average score of 6.96. The next play time with a high sample size is 180 minutes (805 games) and an average rating of 6.87. This was followed by 120 minutes (1,618 games) and 90 minutes (1,591 games) with 6.77 and 6.66 ratings, respectively.

Further analysis of this question could include mutating the data so that games are grouped into play time ranges (i.e., 0-60 mins, 61-120 mins, etc.) and then finding the total average rating of games within those groups.

```{r}

bgg_dataset |>
  group_by(play_time)|>
  summarise(count = n(), average_rating = mean(rating_average, na.rm = TRUE)) |>
  arrange(desc(average_rating))

```

## Q2: How does the complexity of board games vary based on the recommended minimum age?

```{r}
# Assuming bgg_dataset is your dataset of board games
# Calculate the average minimum age
average_min_age <- mean(bgg_dataset$min_age, na.rm = TRUE)
# Print the average minimum age
print(average_min_age)
```

```{r} 
# Assuming bgg_dataset is your dataset of board games
# Calculate the average complexity score
average_complexity <- mean(bgg_dataset$complexity_average, na.rm = TRUE)
# Print the average complexity score
print(average_complexity)
```

```{r}
# Assuming bgg_dataset is your dataset of board games
# Sort the dataset by min_age in descending order and select the top 1251 rows
games_highest_min_age <- bgg_dataset[order(-bgg_dataset$min_age), c('name', 'min_age', 'complexity_average')][1:1251, ]
# Display the list of games with the highest minimum age, sorted by min age requirement
print(games_highest_min_age)
```

```{r}

games_lowest_min_age <- bgg_dataset[order(bgg_dataset$min_age), c('name', 'min_age', 'complexity_average')][1:1251, ]

```

```{r}

#Sort the dataset by min_age in ascending order and select the top 1251 rows
games_lowest_min_age <- bgg_dataset[order(bgg_dataset$min_age), c('name', 'min_age', 'complexity_average')][1:1251, ]
# Display the list of games with the lowest minimum age, sorted by min age requirement
print(games_lowest_min_age)

```

Analysis... Out of the 20,343 board games, we first coded to discover the average minimum age requirement needed to play all of the board games. They ended up having a recommended minimum age requirement of approximately 9.6 years old. In relation to the complexity of the games, we then coded to find the average complexity score, which is around 1.99. After that, we coded to find the lowest minimum age requirement for the list of games in the data set, which was 0. We then filtered the 1,251 games with a 0 minimum age requirement to their corresponding complexity score to spot any notable trends. In relation, we felt like it was necessary to code for the top 1,251 games with the highest minimum age requirement and filtered them with their corresponding complexity score as well. When you consider how the complexity varies based on the recommended minimum age, we found that there is a noticeably higher complexity score for the games with a much lower minimum age requirement than the games with the highest age requirements in the data set of board games.

## ***Project Milestone #4***

For this milestone we were expected to complete the following tasks:

- Shows a draft of data notebook in which you demonstrate substantial progress on the questions you set out to answer at the beginning of the project. This means you should have started on each of them, but you may not have finished.

To recap, our questions are:

- What is the relationship, if any, between average play-time and average rating?
- What are, by count, the most common mechanics among games in our data set? 
- What are the most popular domain types by year?
- Measuring by year and decade, what are the top average board games?
- How does the complexity of board games vary based on the recommended minimum age?

- Has narrative for your code that explains each of your questions, your findings so far and what you do and don't know as a result of them.

- Identifies your most newsworthy finding so far and explain why it is.

Our most newsworthy finding was finding out the most used game mechanics on this list. In a question below, we find that the top five results is as follows: "roll" (6,622), "dice rolling" (5,672), "hand management" (4,152), "set collection" (2,733) and "variable player powers" (variable player powers). This is significant because we can then see how popular games with these mechanics are and make recommendations to game creators about what mechanics they should build games with.

We also think that another potential story idea is a review of the best 2023 games, while also including a narrative on how games have ranked over time as we enter the new year. However, this is ultimately dependent on when we would be able to see that new information.

## Q3: What are, by count, the most common mechanics among games in our data set? 

To find our answer, we made a new data frame grouped by the mechanics column and summarizing the count of mechanics so that we got an idea of the strings that appeared the most within the original data set.

```{r}

mechanics_group <- bgg_dataset |>
  group_by(mechanics) |>
  summarise(mech_count = n()) |>
  arrange(desc(mech_count))
  
```

Next, we began creating a for loop to get a more accurate count of how frequently these mechanics appear in the list, including within columns with nested data. We made a list of the most common strings appearing in our grouped mechanics data frame that we want the loop to search for. Then we created a hash where we stored our key value pairs; the key is our list and the value is the sum of their total mentions. 

Then we made the for loop, which pulls each string one-by-one from our list, cross-references it with our mechanics_group data frame, counts the number of mentions and stores the results in the hash. Then we converted it into a data frame that we could use for further analysis called popular_mechs.

```{r}

mech_list <- list("hand management", "hexagon grid", "dice rolling", "simulation", "set collection", "spin and move", "roll", "pattern recognition", "pattern building", "memory", "cooperative game", "trick-taking", "card drafting", "auction/bidding", "player elimination", "grid movement", "push your luck", "simultaneous action selection", "betting and bluffing", "voting", "area movement", "team-based game", "modular board", "storytelling", "point to point movement", "take that", "variable player powers", "deck bag and pool building", "tile placement", "area majority", "influence", "chit-pull system", "paper-and-pencil", "worker placement", "acting", "network and route building")

h = hash()

for (x in mech_list) {
 df =  mechanics_group |> 
    filter(str_detect(mechanics, x)) |> 
    summarise(mechanics = x, total = sum(mech_count))

  h[[x]] <- df$total

}

```

```{r}

mech_hash_list <- list(mechanics = keys(h), counts = values(h))
popular_mechs <- as.data.frame(mech_hash_list)

```

We arranged the popular_mechs data frame to arrange it in order and identify our most mentioned game mechanics. The top five results is as follows: "roll" (6,622), "dice rolling" (5,672), "hand management" (4,152), "set collection" (2,733) and "variable player powers" (variable player powers).

```{r}

popular_mechs |>
  arrange(desc(counts))

```

We don't know exactly how certain mechanics might impact a game's average rating or rank on the list, but the code block below serves as an example of how we could figure that out if we were to explore this as a continuation of our original project.

We would group by game name, filter and string detect the mechanics column by a specific string, in this case we're used our top result "roll." Then we'd remove almost all of the columns except for name, rating_average, users_rated and bgg_rank. Finally, arrange in descending order by rating_average or bgg_rank.

```{r}

bgg_dataset |>
  group_by(name) |>
  filter(str_detect(mechanics, "roll")) |>
  select(-c(id, year_published, min_players, max_players, play_time, min_age, complexity_average, owned_users, domains, mechanics)) |>
  arrange(desc(rating_average))

```

## Q4: What are the most popular domain types by year?

To find out, we grouped the data by year published and domains, then summarized a count for games in each domain and arranged in descending order by year published and count. 

What was clear from this result was that for the most part strategy games seemed to be at the top spot or within a couple of spots from the top of the list every year. However, there are quite a few games that were ommitted from this list because they did not have a value in the domains column. We also can see that some of the domains are nested within certain rows. Therefore, more work might be needed to get a more representative count of domains.

```{r}

bgg_dataset |>
  group_by(year_published, domains) |>
  summarise(count = n()) |>
  filter(domains != "") |>
  arrange(desc(year_published), desc(count))
  
```

Although the code block below does not give us a breakdown of domains by year, it does help us see a broad distribution of popular domains. This helped us understand a major shortcoming of our original data frame, which is that we're missing domain information from 13,188 games out of 23,343. Also, a quick addition of our values adds up to 23,066, which suggests that we have 277 games that are not represented here as well. Beyond that, the first actual result falls in line with our initial observations which is that strategy games appear the most frequently within our data.

Acquiring the domain information would be something that we'd do if we were to continue working on the project.

```{r}

bgg_dataset |>
  select(domains) |>
  unnest_tokens(bigram, domains, token = "ngrams", n = 2) |>
  separate(bigram, c("word1", "word2"), sep = " ") |>
  mutate(bigram = case_when(
    word1 == "games" & word2 == "party" ~ "party games",
    word1 == "games" & word2 == "children's" ~ "children's games",
    word1 == "games" & word2 == "family" ~ "family games",
    word1 == "games" & word2 == "wargames" ~ "wargames",
    word1 == "games" & word2 == "customizable" ~ "customizable games",
    word1 == "games" & word2 == "strategy" ~ "strategy games",
    word1 == "games" & word2 == "thematic" ~ "thematic games",
    TRUE ~ paste(word1, word2, sep = " ")
  )) |>
  group_by(bigram) |>
  tally(sort = TRUE)

```

## Q5: Measuring by year and decade, what are the top average board games?

Upon looking at the years_published we calculated that there are approximately 84 games with missing unpublished years. We researched and added the year published for top rated games. From there, we categorized games by the following parameters to determine the highest and lowest ranking game per time-period:

Pre-year 0 

Pre-1900
- 1000 to 1499
- 1500 to 1599
- 1600 to 1699
- 1700 to 1799
- 1800 to 1899

Post-1900
We grouped by decade.

```{r}

#arrange by the average rating

bgg_ranking_year <- bgg_dataset |> 
  select(year_published, name, rating_average, domains, mechanics) |> 
  arrange(desc(rating_average))

glimpse(bgg_ranking_year)

bgg_ranking_year

```

Erune came in first place for the highest average rating; however, it did not include the year_published. According to boardgamegeek.com, it was released in 2021. https://boardgamegeek.com/boardgame/275777/erune/credits

```{r}

#making a new data frame with the year_published values
bgg_ranking_year_missing <- tibble(
  name = c("Erune"),
  year_published = c(2021)
) 

bgg_ranking_year_missing <- bgg_ranking_year_missing |> 
  mutate(year_published = as.integer(year_published))

bgg_ranking_year_missing 

```

Top missing board game years to add in:
- War Titans: Invaders Must Die! | 2019 | https://boardgamegeek.com/boardgameversion/323309/kickstarter

- Tindaya | 2022 | https://boardgamegeek.com/boardgame/317511/tindaya/credits

- Thug Lie the Game | 2019 | https://boardgamegeek.com/boardgame/211693/thug-life-game/credits

- Ignite |  2021 | https://boardgamegeek.com/boardgame/260934/ignite/credits

- Moonstone | 2019 | https://www.tabletopgamingnews.com/goblin-king-games-announces-march-release-date-for-moonstone/


```{r}
bgg_ranking_year |> 
  arrange(year_published)

bgg_ranking_year

#there are 84 missing years_published 
```

```{r}

#adding in the top missing years

bgg_ranking_year_missing <- tibble(
  name = c("Erune, Tindaya, Thug Lie the Game, Ignite, Moonstone"),
  year_published = c(2021, 2022, 2019, 2021, 2019)
) 

bgg_ranking_year_missing <- bgg_ranking_year_missing |> 
  mutate(year_published = as.integer(year_published))

bgg_ranking_year_missing 

```

Join the data frames:
Data frame 1: bgg_ranking_year
Data frame 2: bgg_ranking_year_missing

Disclaimer: We used Chat GPT to help join the two data frames, to account for empty values in the column "year_published," while ensuring the values for games without empty values in the data frame "bgg_ranking_year" remained in place. We tested the code for the board game "Erune" and then went back to add in other missing years for the top 20 results. 

https://chat.openai.com/share/621ec676-846d-4eea-8132-29b0eec3ad0e

```{r}
bgg_dataset_year_join <- left_join(bgg_ranking_year, bgg_ranking_year_missing, by = "name") %>%
  mutate(year_published = if_else(year_published.x %in% c("", "0"), year_published.y, year_published.x)) %>%
  select(-year_published.x, -year_published.y)

#checking join by filtering the game Erune
#bgg_dataset_year_join %>%
#  filter(name == "Erune")

bgg_dataset_year_join

```

***Filter and find top game by time-period:***

Pre-year 0
- Before 0

Pre-1900
- 1000 to 1499
- 1500 to 1599
- 1600 to 1699
- 1700 to 1799
- 1800 to 1899

By decade from 1900 onward:
- 1900 to 1909
- 1910 to 1919
- 1920 to 1929
- 1930 to 1939
- 1940 to 1949
- 1950 to 1959
- 1960 to 1969
- 1970 to 1979
- 1980 to 1989
- 1990 to 1999
- 2000 to 2009
- 2010 to 2019
- 2020 to 2022

```{r}

#arrange by year_published
bgg_dataset_year_join |> 
  arrange(year_published)

```

***Games Rated BC***

```{r}

games_bc <- bgg_dataset_year_join |> 
  filter(year_published <= "0") |> 
  arrange(desc(rating_average))

games_bc
  
#highest rating = Go
#lowest rating = Tic-Tac-Toe

```

**Games Rated before 1900**

- 1000 to 1499
Highest Rating = Chu Shogi
Lowest Rating = Fox and Geese

- 1500 to 1599
Highest Rating = Shogi
Lowest Ratingg = Bingo

- 1600 to 1699 
Highest Rating = Cribbage
Lowest Rating = Solitaire

- 1700 to 1799
Highest Rating = Mus
Lowest Rating = Roulette

- 1800 to 1899
Highest Rating = Sheepshead
Lowest Rating = Bunco

```{r}

#plug dates into filter 

games_pre1900 <- bgg_dataset_year_join |> 
  filter(year_published >= "1700" & 
         year_published <= "1799") |> 
  #arrange(desc(rating_average))
  arrange(rating_average)

games_pre1900

```

**Games rated by decade 1900 onward**

- 1900 to 1909
Highest Rating = 500
Lowest Rating = Touring

- 1910 to 1919
Highest Rating = Button Soccer
Lowest Rating = Uncle Wiggily

- 1920 to 1929
Highest Rating = Bridge
Lowest Rating = Cootie

- 1930 to 1939
Highest Rating = American Mah Jongg
Lowest Rating = Slap Jack

- 1940 to 1949
Highest Rating = Subbuteo
Lowest Rating = Candy Land

- 1950 to 1959
Highest Rating = Eleusis
Lowest Rating = Curious George Match-a-Balloon Game

- 1960 to 1969
Highest Rating = Strat-O-Matic Baseball
Lowest Rating = Kreskin's ESP

- 1970 to 1979
Highest Ratingg = Sports Action Canadian Pro Football
Lowest Rating = The Ungame

- 1980 to 1989
Highest Rating = Manassas
Lowest Rating = LCR

- 1990 to 1999
Highest Rating = 1849: The Game of Sicilian Railways
Lowest Rating = Global Survival

- 2000 to 2009
Highest Rating = Gladiatoris
Lowest Rating = Rock Paper Scissors Game

- 2010 to 2019
Highest Rating = TerroriXico
Lowest Rating = Oneupmanship: Mine's Bigger

- 2020 to 2022
Highest Rating = DEFCON 1
Lowest Rating = The Umbrella Academy Game

```{r}

#plug dates into filter 

games_post1900 <- bgg_dataset_year_join |> 
  filter(year_published >= "2020" & 
         year_published <= "2023") |> 
  #arrange(desc(rating_average))
  arrange(rating_average)

games_post1900

```

## ***Project Milestone #5***

This is the last milestone before completing the project. Here is what was expected of us:

Final deliverable. Provide the url of your data analysis notebook, which should include significant portions of narrative along with your code. I should be able to run your notebook from start to finish without errors, with the exception of the file paths for loading large datasets. If you raise a question in your narrative, be sure to answer it. Be sure to describe your most important and newsworthy findings to me as if you were pitching a story about them, including some discussion of what your reporting plans would entail - what would you need/want to do to make this a better story?

Important and/or Newsworthy Findings:

***Keys to success for game makers. An exercise in game design.***
Strategy and family games with a rolling/dice rolling mechanic were some of the most common but also highly rated games in the BGG data. Games with a shorter playtime of usually around 30 minutes had an average rating of 6.17, while longer games with longer playtime saw lower ratings and smaller sample sizes.

We think this is newsworthy because it's valuable for creators to see game design aspects that can contribute to either higher ratings or toward increasing sales and replayability. We'd like to talk to some of the designers of top games on our list to get their thoughts about our findings. What expectations in terms of ratings or sales might they have with creating a game geared toward strategy or family domains? How do they feel about rolling and dice rolling appearing as a common mechanic and what does that element bring to a game? How do they feel about the popularity of shorter playtime versus longer playtime? What are the challenges in creating a shorter game that can be played infinitely? From their experience, what are mechanics or domains they've found to be important contributors to successful games? Conversely, what have they found to not be popular among players?

***Catan stands the test of time...and popular opinion.***
Published in 1995, Catan is the third most rated game in the BGG rankings (101,510 ratings) with an average rating of 7.15. Also impressive is the fact that four out of the top five most rated games are considered family games and strategy games. Each of these games carried ratings above 7, which is notable considering it's harder to achieve a high average rating with a large sample size. The only two games with more user ratings than Catan were Pandemic (102,214 ratings and 7.61 average rating) and Carcassonne (101,853 ratings and 7.42 average). Catan is also the second-most owned game in the rankings behind Pandemic.

If we were to continuing reporting on this story, we'd probably want to cross-reference Catan's BGG ranking with other comparable ranking sites. We could utilize user reviews from websites selling the game and even seek out board game communities, game stores or enthusiasts who hold playing sessions to get their thoughts about the game. Some questions we'd ask are:
- What are the social aspects of the game that you enjoy? Why do you think Catan is still relevant almost two decades after its inception? What is your relationship with the game, when were you introduced to it and how does it compare to other board games you've played over the years? Is it worthy of being one of the most-played and highest-rated games of all time? 

***Go is the most popularly rated Before Common Era (BC) game.***
The game has an average rating of 7.64 and ranks 173 overall in the BGG list. Conversely, Tic-Tac-Toe was the worst-rated BC era game with a 2.68 average rating and was nearly last in the list in general.

We think it would be fun to do a historical profile of the game. What are its exact origins? What's its cultural meaning? What aspects of the game have and haven't changed over the centuries since its introduction? What factors have contributed to its longevity? How was it impacted when translated to digital/online versions? We'd need to speak with Go experts, board game historians and find communities with players that can speak on how the game has impacted their lives.

***Review the Top Games of 2023***
As mentioned in milestone four, we'd like to review the best games of 2023. Specifically, we'd like to see if the top games from this year possess aspects that align with some of the top games from our data set. For example, are games this year geared toward strategy/family domains? What are their primary mechanics? Which games are highest in average rating versus the number of owned users? 

To accomplish this, we'd have to gather sale information from a number of different retailers, as well as conduct an analysis of user reviews across a number of websites or databases to obtain a reasonable sample size.
