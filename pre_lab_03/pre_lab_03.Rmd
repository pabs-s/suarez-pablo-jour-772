---
title: "pre_lab_03.Rmd"
author: "Derek Willis"
date: "2023-08-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

## About this notebook

This notebook contains code and explanatory text that your should review and run as you read through two chapters on data cleaning from the course textbook, "Data Journalism with R and the Tidyverse". Answer questions and edit the document as directed.

Running this notebook will help you understand key data analysis methods and concepts that you will put into practice during this week's lab.

When you are finished running the code in this notebook, you will push changes to your course GitHub repo, and upload the link to ELMS as instructed.

## Data Cleaning, Part I

### Task 1: Load libraries and settings

**Task** Run the following code in the gray-colored codeblock below to load the tidyverse library and turn off scientific notation.

```{r}
# Remove scientific notation
options(scipen=999)
# Load the tidyverse   
library(tidyverse)
```

### Task 2: Load data

**Task** Load some [Maryland state government payments data](https://opendata.maryland.gov/Budget/State-of-Maryland-Payments-Data-FY2008-to-FY2024/7syw-q4cy) by running the following code. We'll use the guess_max() function as an argument to use the first 10 rows to set the data type. What does the first line of the red Warning message that prints out when you load the data say? What happens when you follow its instructions? Answer below. 
**Answer: The warning line says "one or more parsing issues" and to call 'problems()' in my data frame. After calling in problems, it creates a table showing the rows within the imported data where the parsing issues exist.**

```{r}
#payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024.csv", guess_max=10)

problems(payments)

```

### Task 3: Reload data

**Task** Run the following codeblock to reload the data, using every row to set the data types. Does it show any parsing errors when you run? Answer below 
**Answer: There are no apparent parsing issues.**

```{r}
payments <- read_csv("data/State_of_Maryland_Payments_Data__FY2008_to_FY2024.csv", guess_max=373564)
```

### Task 4: Examine the data with glimpse

**Task** Run the following codeblock to glimpse the data. What data type is the "Vendor Name" field? What data type is the "Amount" field? What data type is the "Date" column? Answer below. 
**Answer: The vendor name field is a character type, the amount field is a double and the date column is also a character type.**

```{r}
glimpse(payments)
```

Things that should be characters -- like agency name, vendor name -- are characters (chr). Things that should be numbers (dbl) -- like amount and fiscal year -- are numbers. We've seen before that sometimes dates aren't defined as date datatypes by R - we can fix that using `lubridate`.

### Task 5: Detect wrong spatial data

The second smell we can find in code is **wrong spatial data**. Spatial data means data that refers to some geography; in this dataset the only geographical element is the vendor's zip code. Zip codes should be, at a minimum, five characters long (although composed of numbers, zip codes aren't used as numbers).

We can check to see if any of the zip codes are less than five characters by using [a function called `str_length`](https://stringr.tidyverse.org/reference/str_length.html) inside a filter.

**Task** Run the following codeblock to group by the vendor's zip code and show any that are less than five characters in length. How many zip codes do not have five characters? What do you think explains those records? 
**Answer: There are 549 zip codes that do not have five characters (based on the number of rows the codeblock gives us). These results may not have five characters because it's possible that they start with a zero and the zero is not being registered.**

```{r}
payments |>
  group_by(`Vendor Zip`) |>
  filter(str_length(`Vendor Zip`) < 5) |> 
  summarise(
    count=n()
  ) |>
  arrange(desc(count))
```

### Task 6: Load Maryland grant and loan data

Let's now look at **gaps in data**. These often occur when you have a date or time element in your data, but there are other potential gaps, too. To illustrate those, we're going to introduce some Maryland state grant and loan data from 2009 forward. Let's load it and take a look:

**Task** Run the following codeblock to load Maryland state government grant and loan data

```{r}
md_grants_loans <- read_csv("data/State_of_Maryland_Grant_and_Loan_Data__FY2009_to_FY2022.csv")
```

Each row represents a recipient of state grant or loan, along with information about their location and the state agency that provided the money. When we talk about gaps, often they indicate the administrative rules. Here's an example: let's count the number of payments in each category (Grant or Loan) by year in this dataset.

### Task 7: Looking at categories

**Task** Run the following codeblock and describe below what each line is doing. Looking at the results, what jumps out at you as potentially problematic? 
**Answer: The code is pulling in the md_grants_loans datasheet, grouping the data by the fiscal year and category columns, it's then counting the number of instances for each pair of fiscal year and category and then arranging by fiscal year in ascending order. Some problems I noticed are that we're seeing NA in some parts of the category column (which have extremely low values), as well as incomplete/unknown characters like L.**

```{r}
md_grants_loans |> 
  group_by(`Fiscal Year`, Category) |> 
  summarize(count = n()) |> 
  arrange(`Fiscal Year`)
```

Any time you are going to focus on a column for analysis, you should check for unusual values. Are there any unusually large values or unusually small values? Are there any values that raise immediate questions about the data? Let's look at the smallest amounts in the grants and loan data.

### Task 8: Find outliers

**Task** Run the following code to arrange the grants & loan data so that the smallest amount is first. Describe what you see. 
**Answer: The code is arranged from smallest to largest values as intended. Some observations include some zip codes include the extra four digits at the end, as well as the fact that the grantee name and description have different capitalization properties within their columns. Also, the fiscal period is 1 for every row and the date is always 6/30/XX at 12:00 AM. **

```{r}
md_grants_loans |> 
  arrange(Amount)
```

## Data Cleaning, Part II

### Task 1: Install janitor

**Task** Run the following codeblock to install the janitor package.

```{r}
install.packages('janitor')
```

### Task 2: Load janitor

**Task** Run the following code to load janitor.

```{r}
library(janitor)
```

Let's continue with our Maryland grants and loans data that we worked with in the previous chapter. There are a number of issues with this data set that might get in the way of asking questions and receiving accurate answers. They are:

-   The column names have spaces in them. This isn't a deal-breaker, as we used this dataframe previously. But it does require that you do some things differently when writing code, and ideally you don't want spaces in your column names.
-   Inconsistent capitalization across multiple columns. Sometimes the grantee is capitalized, and other times not. Portions of the grantor name are sometimes capitalized. This issue will ruin your ability to count and add things using those columns.
-   The zip field mixes five digit ZIP codes and nine digit ZIP codes, and some of the records include spaces. If we wanted to group and count the number of loans in a given ZIP code, this inconsistency would not let us do that correctly.
-   The category column is inconsistent and has some missing values.

Let's get cleaning. Our goal will be to build up one block of code that does all the necessary cleaning in order to answer this question: which zip code has gotten the most amount of money from the Maryland Tourism Board?

### Task 3: Use clean_names()

**Task** Run the following codeblock to use the `clean_names()` function from janitor to standardize column names. How does it change the headers? Answer below.
**Answer: The code has changed all of the headers to a lowercase format.**

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 4: Use rename()

**Task** Run the following codeblock to use the clean_names() function from janitor to standardize column names and then use rename() to change the "grantor" column to "source". With `rename()` the new name comes first!

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor)

# display the cleaned dataset
cleaned_md_grants_loans
```

Right now the `source`, `grantee` and `description` columns have inconsistent capitalization. We can fix that using a mutate statement and a function that changes the case of text called `str_to_upper()`. We'll use the same columns, overwriting what's in there since all we're doing is changing case.

### Task 5: Using str_to_upper() to standardize case

**Task** Run the following codeblock to use str_to_upper() to make the source, grantee and description columns upper-cased. Describe what each line is doing.
**Answer: Each column has now been formatted to be entirely capitalized, except for category because it was not listed among the mutate code. ** 

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 6: Check for duplicate rows

**Task** Run the following codeblock to check for duplicate rows using get_dupes(). How many duplicates are possible? 
**Answer: There are 50 rows, which should signify that there are 25 dupes.**

```{r}
cleaned_md_grants_loans |>
  get_dupes()
```

### Task 7: Get rid of duplicate rows

**Task** Run the following codeblock to use distinct() to get rid of duplicate rows. How many rows does the new dataframe have? Answer below. 
**Answer: This new dataframe has 17,740 rows.**

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct()

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 8: Clean up ZIP code

The rest of the problems with this data set all have to do with inconsistent format of values in a few of the columns. To fix these problems, we're going to make use of mutate() in concert with "string functions" -- special functions that allow us to clean up columns stored as character strings. The tidyverse package `stringr` has lots of useful string functions that you can look up!

Let's start by cleaning up the zip field. Remember, some of the rows had a five-digit ZIP code, while others had a nine-digit ZIP code, separated by a hyphen or not.

We're going to write code that tells R to make a new column for our zips, keeping the first five digits on the left, and get rid of anything after that by using `mutate()` in concert with `str_sub()`, from the `stringr` package.

**Task** Run the following codeblock to use str_sub() to convert the ZIP codes that have nine digits to five digits, creating a new column. Look at the difference in the result - what changed? 
**Answer: The codeblock created a new column at the end that contains the five digit zip code for each row. This allows us to better organize the data without drastically affecting the raw data.**

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L))


# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 9: Clean up zip5 field more with case_when()

**Task** Run the following codeblock to use case_when() to change clear non-zip codes into NA values.

```{r}
# cleaning function
cleaned_md_grants_loans <- md_grants_loans |>
  clean_names() |> 
  rename(source = grantor) |> 
  mutate(source = str_to_upper(source), grantee = str_to_upper(grantee), description = str_to_upper(description)) |> 
  distinct() |>
  mutate(zip5 = str_sub(zip_code, start=1L, end=5L)) |>
  mutate(zip5 = case_when(
    zip5 == "Vario" ~ NA,
    zip5 == "UB7 O" ~ NA,
    zip5 == "UB7 " ~ NA,
    .default = zip5
  ))

# display the cleaned dataset
cleaned_md_grants_loans
```

### Task 10: Answer our question!

**Task** Write and run code to answer our original question: which zip code has gotten the most amount of money from the Maryland Tourism Board? Where is that zip code, and does that zip code make sense to you as the top recipient? Write a sentence describing the top result.
**Answer: The zip code with the most amount of money from the Maryland Tourism Board is 21202, which is Baltimore. The zip code makes sense to me as the top result given that Baltimore probably generates the most tourism for the state.**

```{r}
cleaned_md_grants_loans |>
group_by(zip5) |>
filter(str_detect(source, "MARYLAND TOURISM BOARD")) |>
summarise(total_amount = sum(amount)) |>
arrange(desc(total_amount))
```
